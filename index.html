<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Face Filter App</title>
  <style>
    canvas, video {
      position: absolute;
      left: 0;
      top: 0;
    }
    #wrapper {
      position: relative;
      width: 640px;
      height: 480px;
      margin: auto;
    }
  </style>
</head>
<body>
  <h2 style="text-align:center;">ðŸ˜Ž Face Filter App (Snapchat Style)</h2>
  <div id="wrapper">
    <video id="video" width="640" height="480" autoplay muted></video>
    <canvas id="overlay" width="640" height="480"></canvas>
  </div>

  <!-- Face API scripts -->
  <script defer src="https://cdn.jsdelivr.net/npm/face-api.js"></script>

  <script>
    const video = document.getElementById('video');
    const canvas = document.getElementById('overlay');
    const context = canvas.getContext('2d');

    async function setupCamera() {
      const stream = await navigator.mediaDevices.getUserMedia({ video: {} });
      video.srcObject = stream;
      return new Promise((resolve) => {
        video.onloadedmetadata = () => {
          resolve(video);
        };
      });
    }

    async function loadModels() {
      const MODEL_URL = 'https://cdn.jsdelivr.net/npm/face-api.js/models';
      await faceapi.nets.tinyFaceDetector.loadFromUri(MODEL_URL);
      await faceapi.nets.faceLandmark68Net.loadFromUri(MODEL_URL);
    }

    function drawGlasses(landmarks) {
      const leftEye = landmarks.getLeftEye();
      const rightEye = landmarks.getRightEye();

      const eyeWidth = rightEye[3].x - leftEye[0].x;
      const eyeHeight = 30;

      const x = leftEye[0].x;
      const y = leftEye[0].y - 15;

      context.fillStyle = 'rgba(0, 0, 0, 0.7)';
      context.fillRect(x, y, eyeWidth + 10, eyeHeight);

      // Add white dots as â€œshineâ€ for fun
      context.fillStyle = '#fff';
      context.beginPath();
      context.arc(x + 10, y + 10, 4, 0, Math.PI * 2);
      context.fill();
    }

    async function startFaceFilter() {
      await loadModels();
      await setupCamera();

      setInterval(async () => {
        const detections = await faceapi.detectSingleFace(video, new faceapi.TinyFaceDetectorOptions())
                                        .withFaceLandmarks();

        context.clearRect(0, 0, canvas.width, canvas.height);

        if (detections && detections.landmarks) {
          drawGlasses(detections.landmarks);
        }
      }, 100);
    }

    startFaceFilter();
  </script>
</body>
</html>
