<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Face Filter App</title>
  <style>
    canvas, video {
      position: absolute;
      left: 0;
      top: 0;
    }
    #wrapper {
      position: relative;
      width: 640px;
      height: 480px;
      margin: auto;
    }
  </style>
</head>
<body>
  <h2 style="text-align:center;">ðŸ˜Ž Face Filter App</h2>
  <div id="wrapper">
    <video id="video" width="640" height="480" autoplay muted></video>
    <canvas id="overlay" width="640" height="480"></canvas>
  </div>

  <!-- Face API script -->
  <script defer src="https://cdn.jsdelivr.net/npm/face-api.js"></script>

  <script>
    const video = document.getElementById('video');
    const canvas = document.getElementById('overlay');
    const context = canvas.getContext('2d');

    async function setupCamera() {
      try {
        const stream = await navigator.mediaDevices.getUserMedia({ video: true });
        video.srcObject = stream;
        return new Promise((resolve) => {
          video.onloadedmetadata = () => resolve();
        });
      } catch (err) {
        alert("ðŸ˜¢ Camera access denied or unavailable.");
        console.error(err);
      }
    }

    async function loadModels() {
      const MODEL_URL = 'https://cdn.jsdelivr.net/npm/face-api.js/models';
      await faceapi.nets.tinyFaceDetector.loadFromUri(MODEL_URL);
      await faceapi.nets.faceLandmark68Net.loadFromUri(MODEL_URL);
    }

    function drawGlasses(landmarks) {
      const leftEye = landmarks.getLeftEye();
      const rightEye = landmarks.getRightEye();

      const eyeWidth = rightEye[3].x - leftEye[0].x;
      const x = leftEye[0].x;
      const y = leftEye[0].y - 20;

      context.fillStyle = 'rgba(0, 0, 0, 0.7)';
      context.fillRect(x, y, eyeWidth + 20, 30);

      context.fillStyle = '#fff';
      context.beginPath();
      context.arc(x + 10, y + 10, 4, 0, Math.PI * 2);
      context.fill();
    }

    async function startApp() {
      await loadModels();
      await setupCamera();

      setInterval(async () => {
        const detections = await faceapi
          .detectSingleFace(video, new faceapi.TinyFaceDetectorOptions())
          .withFaceLandmarks();

        context.clearRect(0, 0, canvas.width, canvas.height);

        if (detections && detections.landmarks) {
          drawGlasses(detections.landmarks);
        }
      }, 100);
    }

    startApp();
  </script>
</body>
</html>
